---
title: "Homework6"
author: "Yunjia Liu"
date: "2024-12-02"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(modelr)
```

## Probelm 1

1. Load the dataset.

```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") |>
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) |>
  select(name, id, everything())
```


2. A function to calculate the r-squared and log(beta0 * beta1) \
First, establish a linear model between t_max and t_min. Then, we calculate the desired coefficient.

```{r}
compute_stats = function(data) {
  model = lm(tmax ~ tmin, data = data)
  glance_model = broom::glance(model)
  tidy_model = broom::tidy(model)
  
  r_squared = glance_model$r.squared
  
  beta0 = tidy_model$estimate[tidy_model$term == "(Intercept)"]
  beta1 = tidy_model$estimate[tidy_model$term == "tmin"]
  
  log_beta0_beta1 = log(abs(beta0 * beta1))
  return(tibble(r_squared = r_squared, log_beta0_beta1 = log_beta0_beta1))
}
```

3. A quick function to generate our bootstrap samples
```{r}
boot_sample = function(df) {
  sample_frac(df, replace = TRUE)
}
```

4. Perform bootstrap and compute r^2 and log(beta0 * beta1)
```{r}
n_boot = 5000
set.seed(123)

boot_straps =
  tibble(strap_number = 1:n_boot) |>
  mutate(
    strap_sample = map(strap_number, ~ boot_sample(weather_df)),  
    stats = map(strap_sample, compute_stats)
  )
```


5. Extract results into a tidy format.

```{r}
boot_results = 
  boot_straps |>
  unnest_wider(stats)
```

6. Calculate the 95% confidence intervals for r^2 and log(beta0 * beta1).

```{r}
ci_r_squared = quantile(boot_results$r_squared, c(0.025, 0.975))
ci_log_beta0_beta1 = quantile(boot_results$log_beta0_beta1, c(0.025, 0.975))

cat("95% CI for r^2: ", ci_r_squared, "\n")
cat("95% CI for log(beta0 * beta1): ", ci_log_beta0_beta1, "\n")
```

7. Plot distributions of two estimates (r^2 and log(beta0 * beta1))

```{r}
ggplot(boot_results, aes(x = r_squared)) +
  geom_histogram(binwidth = 0.01, color = "black", fill = "blue", alpha = 0.7) +
  labs(title = "Bootstrap Distribution of r^2", x = "r^2", y = "Frequency") +
  theme(
    plot.title = element_text(hjust = 0.5)
  )

ggplot(boot_results, aes(x = log_beta0_beta1)) +
  geom_histogram(binwidth = 0.05, color = "black", fill = "red", alpha = 0.7) +
  labs(title = "Bootstrap Distribution of log(beta0 * beta1)", x = "log(beta0 * beta1)", y = "Frequency") +
  theme(
    plot.title = element_text(hjust = 0.5)
  )
```

## Problem 2

1. Load the dataset and mutate the variables according to the requirement. \ 

   Create a city_state variable and a binary variable indicating whether the homicide is solved. Omit cities Dallas, TX; Phoenix,      AZ; and Kansas City, MO  and Tulsa, AL. filter the **victim_race** to limit analysis for whom victim_race is white or black. Take    'Unknown' as na and convert the **victim_age**.

```{r}
homocide_data = read_csv("./data/homicide-data.csv",,na = c("", "NA", "N/A","Unknown"))

homocide_data =
  homocide_data |>
  janitor::clean_names() |>
  mutate(
    city_state = paste(city, state, sep = ", "),
    solved = ifelse(disposition == "Closed by arrest", 1, 0),
    victim_age = as.numeric(victim_age)
  ) |>
  filter(
    !(city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL")),
    victim_race %in% c("White", "Black"),
    !is.na(victim_age)
  )
```

2. Logistic Regression for Baltimore, MD \

  use the `glm` function to fit a logistic regression with resolved vs unresolved as the outcome and victim age, sex and race as      predictors.
```{r}
baltimore_data =
  homocide_data |>
  filter(city_state == "Baltimore, MD")

baltimore_model = glm(
  solved ~ victim_age + victim_sex + victim_race,
  data = baltimore_data
)

saveRDS(baltimore_model, file = "model/baltimore_glm_model.rds")

```

3. For Baltimore,MD: obtain the estimate and confidence interval of the adjusted odds ratio for solving homicides comparing male victims to female victims keeping all other variables fixed.

```{r}
baltimore_loaded_model = readRDS("model/baltimore_glm_model.rds")

baltimore_or = 
  broom::tidy(baltimore_loaded_model) |>
  filter(term == "victim_sexMale") |>
  mutate(
    OR = exp(estimate),
    CI_lower = exp(estimate - 1.96 * std.error),
    CI_upper = exp(estimate + 1.96 * std.error)
  )

baltimore_or |>
  knitr::kable(digits = 3)
```


4. Logistic Regression for All Cities. \ 

run `glm` for each of the cities in dataset, and extract the adjusted odds ratio (and CI) for solving homicides comparing male victims to female victims. 
```{r}
city_models =
  homocide_data |> 
  group_by(city_state) |> 
  nest() |> 
  mutate(
    model = map(data, ~ glm(solved ~ victim_age + victim_sex + victim_race, data = ., family = binomial())),
    results = map(model, ~ broom::tidy(.) |> 
                    filter(term == "victim_sexMale") |> 
                    mutate(
                      OR = exp(estimate),
                      CI_lower = exp(estimate - 1.96 * std.error),
                      CI_upper = exp(estimate + 1.96 * std.error)
                    ))
  ) |> 
  unnest(results) |> 
  select(city_state, term, OR, CI_lower, CI_upper, p.value)

city_models |> 
  knitr::kable(digits = 3)
```


5. Visualize the results by plotting the ORs and confidence intervals for each city and organize cities according to estimated OR.
```{r}
city_models |>
  mutate(city_state = fct_reorder(city_state, OR)) |>
  ggplot(aes(x = city_state, y = OR)) +
  geom_point() +
  geom_errorbar(aes(ymin = CI_lower, ymax = CI_upper), width = 0.2) +
  coord_flip() +
  labs(
    title = "Adjusted Odds Ratios for Solving Homicides by City",
    x = "City",
    y = "Adjusted Odds Ratio (Male vs. Female Victims)"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5)
  )

```


- The adjusted odds ratios (ORs) for solving homicides comparing male victims to female victims vary widely across cities, indicating differences in how male and female homicide cases are resolved depending on the location. Cities like Albuquerque, NM, Stockton, CA, and Fresno, CA show ORs greater than 2, suggesting that male victim cases are much more likely to be solved compared to female victim cases in these locations. Some cities, such as Baton Rouge, LA, and New York, NY, have ORs below 1, implying that female victim cases are more likely to be solved compared to male victim cases in these locations.
- Certain cities (e.g., Albuquerque, NM) have wide confidence intervals, suggesting a high degree of uncertainty in the OR estimates due to variability or limited data. These results should be interpreted cautiously.


## Problem 3
```{r}
birthweight_data = read_csv("./data/birthweight.csv")

# Convert categorical variables to factors
birthweight_data = birthweight_data |>
  mutate(
    babysex = factor(babysex, levels = c(1, 2), labels = c("Male", "Female")),
    malform = factor(malform, levels = c(0, 1), labels = c("Absent", "Present")),
    frace = factor(frace),
    mrace = factor(mrace)
  )

summary(birthweight_data)

# Check for missing data
colSums(is.na(birthweight_data))

# View structure of the dataset
str(birthweight_data)
```


```{r}
# Fit the model
birthweight_model = lm(bwt ~ gaweeks + blength + bhead + delwt + momage + smoken, 
                        data = birthweight_data)

# View the summary of the model
summary(birthweight_model)

# Add predictions and residuals to the dataset
birthweight_data = birthweight_data |>
  add_predictions(birthweight_model) |>
  add_residuals(birthweight_model)

# Plot residuals against fitted values
ggplot(birthweight_data, aes(x = pred, y = resid)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  labs(title = "Residuals vs Fitted Values", 
       x = "Fitted Values", 
       y = "Residuals") +
  theme_minimal()

```


```{r}
model1 = lm(bwt ~ blength + gaweeks, data = birthweight_data)
summary(model1)

model2 = lm(bwt ~ bhead + blength + babysex + bhead * blength + blength * babysex + bhead * babysex + bhead * blength * babysex, data = birthweight_data)
summary(model2)

```




```{r}
cv_results = 
  crossv_mc(birthweight_data, n = 100) |>
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble),
    model_proposed  = map(train, \(df) lm(bwt ~ gaweeks + blength + bhead + delwt + momage + smoken, data = birthweight_data)),
    model1  = map(train, \(df) lm(bwt ~ blength + gaweeks, data = birthweight_data)),
    model2  = map(train, \(df) lm(bwt ~ bhead + blength + babysex + bhead * blength + blength * babysex + bhead * babysex + bhead * blength * babysex, data = birthweight_data)),
    mse_proposed = map2_dbl(model_proposed, test, \(mod, df) rmse(model = mod, data = birthweight_data)),
    mse_model1 = map2_dbl(model1, test, \(mod, df) rmse(model = mod, data = birthweight_data)),
    mse_model2 = map2_dbl(model2, test, \(mod, df) rmse(model = mod, data = birthweight_data))
  )
  
# Summarize mean squared error for each model
cv_summary <- cv_results %>%
  summarize(
    mse_proposed = mean(mse_proposed),
    mse_model1 = mean(mse_model1),
    mse_model2 = mean(mse_model2)
  )

cv_summary |> knitr::kable(digits = 3)
```

